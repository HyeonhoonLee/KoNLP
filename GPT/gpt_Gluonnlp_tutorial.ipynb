{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt-02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HyeonhoonLee/KoNLP/blob/master/GPT/gpt_Gluonnlp_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81YQ41Jq3ioY"
      },
      "source": [
        "## GPT 구현 과정 (2/2)\n",
        "![](https://raw.githubusercontent.com/paul-hyun/paul-hyun.github.io/master/assets/2019-12-30/gpt-model-downstream.png)\n",
        "\n",
        "GPT 모델 구현에 대한 설명 입니다.\n",
        "\n",
        "이 내용을 확인하기 전 아래 내용을 확인하시기 바랍니다.\n",
        "- [Sentencepiece를 활용해 Vocab 만들기](https://paul-hyun.github.io/vocab-with-sentencepiece/)\n",
        "- [Naver 영화리뷰 감정분석 데이터 전처리 하기](https://paul-hyun.github.io/preprocess-nsmc/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (1/3)](https://paul-hyun.github.io/transformer-01/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (2/3)](https://paul-hyun.github.io/transformer-02/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (3/3)](https://paul-hyun.github.io/transformer-03/)\n",
        "- [GPT(Generative Pre-Training) 구현하기 (1/2)](https://paul-hyun.github.io/gpt-01/)\n",
        "\n",
        "[Colab](https://colab.research.google.com/)에서 실행 했습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRRoo-bl4G_P"
      },
      "source": [
        "#### 0. Pip Install\n",
        "필요한 패키지를 pip를 이용해서 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCCS8nPM4KZu",
        "outputId": "3834074b-473a-4f40-bac6-2f4bd1598b00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install sentencepiece\n",
        "!pip install wget"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 21.7MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 29.4MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 24.0MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 21.8MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 22.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61kB 16.2MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 17.3MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 17.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92kB 16.1MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 16.9MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112kB 16.9MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122kB 16.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133kB 16.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143kB 16.9MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153kB 16.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 174kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 245kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 276kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 16.9MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.94\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=1bb4cdd14dcca5109f80195bb1f1b8af8da293f3690976486ae41fd98d64fb42\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTSjMFUn4XUn"
      },
      "source": [
        "#### 1. Google Drive Mount\n",
        "Colab에서는 컴퓨터에 자원에 접근이 불가능 하므로 Google Drive에 파일을 올려 놓은 후 Google Drive를 mount 에서 로컬 디스크처럼 사용 합니다.\n",
        "1. 아래 블럭을 실행하면 나타나는 링크를 클릭하세요.\n",
        "2. Google 계정을 선택 하시고 허용을 누르면 나타나는 코드를 복사하여 아래 박스에 입력한 후 Enter 키를 입력하면 됩니다.\n",
        "\n",
        "학습관련 [데이터 및 결과 파일](https://drive.google.com/open?id=15XGr-L-W6DSoR5TbniPMJASPsA0IDTiN)을 참고 하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnP2WIF83a10",
        "outputId": "eb08f26a-5855-40ba-bf97-11d6a2763325",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB_KRnu3sJq_"
      },
      "source": [
        "# data를 저장할 폴더 입니다. 환경에 맞게 수정 하세요.\n",
        "data_dir = \"/content/drive/My Drive/ModelCollection/transformer-evolution\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-JuqiLd4eTg"
      },
      "source": [
        "#### 2. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzUV7QadJMIl",
        "outputId": "4b5e0576-89f1-4960-d739-2d2704f32bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        }
      },
      "source": [
        "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html --upgrade"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.6.0+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.6.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (708.0MB)\n",
            "\u001b[K     |████████████████████████████████| 708.0MB 26kB/s \n",
            "\u001b[?25hCollecting torchvision==0.7.0+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.7.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (5.9MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9MB 69.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0+cu101) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0+cu101) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.7.0+cu101) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "  Found existing installation: torchvision 0.8.1+cu101\n",
            "    Uninstalling torchvision-0.8.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.8.1+cu101\n",
            "Successfully installed torch-1.6.0+cu101 torchvision-0.7.0+cu101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHPMeWxJ4fc_"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from tqdm import tqdm, tqdm_notebook, trange\n",
        "import sentencepiece as spm\n",
        "import wget\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awf2SXuQ4zj0"
      },
      "source": [
        "#### 3. 폴더의 목록을 확인\n",
        "Google Drive mount가 잘 되었는지 확인하기 위해 data_dir 목록을 확인 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk2mg8dO44bo",
        "outputId": "1ba73013-e8b6-49bd-84ec-ed2998e01820",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for f in os.listdir(data_dir):\n",
        "  print(f)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kowiki.csv.gz\n",
            "kowiki.model\n",
            "kowiki.vocab\n",
            "ratings_train.txt\n",
            "ratings_test.txt\n",
            "ratings_train.json\n",
            "ratings_test.json\n",
            "kowiki.txt\n",
            "kowiki_gpt.json\n",
            "save_gpt_pretrain.pth\n",
            "kowiki_bert_0.json\n",
            "save_bert_pretrain.pth\n",
            "kowiki_t5.model\n",
            "kowiki_t5.vocab\n",
            "kowiki_t5_0.json\n",
            "save_t5_pretrain.pth\n",
            "ratings_train_t5.json\n",
            "ratings_test_t5.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNEHoBw046_r"
      },
      "source": [
        "#### 4. Vocab 및 입력\n",
        "\n",
        "[Sentencepiece를 활용해 Vocab 만들기](https://paul-hyun.github.io/vocab-with-sentencepiece/)를 통해 만들어 놓은 vocab을 로딩 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr8lRSRtB2WF",
        "outputId": "74319af4-ae2b-4c12-d773-0c32eb7616cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install gluonnlp"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gluonnlp in /usr/local/lib/python3.6/dist-packages (0.10.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (0.29.21)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (20.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->gluonnlp) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->gluonnlp) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60fDjygYB6rH",
        "outputId": "f09dd842-6713-415f-aaa8-0032b22ea38b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install mxnet"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mxnet in /usr/local/lib/python3.6/dist-packages (1.7.0.post1)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet) (0.8.4)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (1.18.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwDURJiYBz1L"
      },
      "source": [
        "# To use the word vocab API (https://nlp.gluon.ai/api/vocab.html).\n",
        "import gluonnlp as nlp \n",
        "\n",
        "from gluonnlp.data import SentencepieceTokenizer"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI3scr5FBkvy"
      },
      "source": [
        "BASE_MODEL_PATH = '/content/drive/My Drive/ModelCollection/gpt_ckpt/'"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLLzDzSzBlhL"
      },
      "source": [
        "TOKENIZER_PATH = os.path.join(BASE_MODEL_PATH + 'gpt2_kor_tokenizer.spiece')\n",
        "\n",
        "# # To make tokenizer for KoGPT2.\n",
        "tokenizer = SentencepieceTokenizer(TOKENIZER_PATH)\n",
        "\n",
        "# To define the word dictionary.\n",
        "vocab = nlp.vocab.BERTVocab.from_sentencepiece(TOKENIZER_PATH,\n",
        "                                               mask_token=None,\n",
        "                                               sep_token=None,\n",
        "                                               cls_token=None,\n",
        "                                               unknown_token='<unk>',\n",
        "                                               padding_token='<pad>',\n",
        "                                               bos_token='<s>',\n",
        "                                               eos_token='</s>')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liXKjo4B4-2I"
      },
      "source": [
        "# # vocab loading\n",
        "# vocab_file = f\"{data_dir}/kowiki.model\"\n",
        "# vocab = spm.SentencePieceProcessor()\n",
        "# vocab.load(vocab_file)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sSGFxCl5Chp"
      },
      "source": [
        "#### 5. Config\n",
        "\n",
        "모델에 설정 값을 전달하기 위한 config를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OGdB1HN5CDj"
      },
      "source": [
        "\"\"\" configuration json을 읽어들이는 class \"\"\"\n",
        "class Config(dict): \n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file):\n",
        "        with open(file, 'r') as f:\n",
        "            config = json.loads(f.read())\n",
        "            return Config(config)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLT7pzxa5IFA",
        "outputId": "8495f214-442c-4ed5-ff56-baa3b129686c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "config = Config({\n",
        "    \"n_dec_vocab\": len(vocab),\n",
        "    \"n_dec_seq\": 256,  ##256\n",
        "    \"n_layer\": 6,\n",
        "    \"d_hidn\": 256,    ##256\n",
        "    \"i_pad\": 3,\n",
        "    \"d_ff\": 1024,    ##1024\n",
        "    \"n_head\": 4,\n",
        "    \"d_head\": 64,\n",
        "    \"dropout\": 0.1,\n",
        "    \"layer_norm_epsilon\": 1e-12\n",
        "})\n",
        "print(config)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_dec_vocab': 50000, 'n_dec_seq': 256, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 3, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEeHBOSf5M7Z"
      },
      "source": [
        "#### 6. GPT\n",
        "\n",
        "GPT Class 및 함수 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR9Yz5Hf5Rci"
      },
      "source": [
        "\"\"\" sinusoid position encoding \"\"\"\n",
        "def get_sinusoid_encoding_table(n_seq, d_hidn):\n",
        "    def cal_angle(position, i_hidn):\n",
        "        return position / np.power(10000, 2 * (i_hidn // 2) / d_hidn)\n",
        "    def get_posi_angle_vec(position):\n",
        "        return [cal_angle(position, i_hidn) for i_hidn in range(d_hidn)]\n",
        "\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # even index sin \n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # odd index cos\n",
        "\n",
        "    return sinusoid_table\n",
        "\n",
        "\n",
        "\"\"\" attention pad mask \"\"\"\n",
        "def get_attn_pad_mask(seq_q, seq_k, i_pad):\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    pad_attn_mask = seq_k.data.eq(i_pad).unsqueeze(1).expand(batch_size, len_q, len_k)  # <pad>\n",
        "    return pad_attn_mask\n",
        "\n",
        "\n",
        "\"\"\" attention decoder mask \"\"\"\n",
        "def get_attn_decoder_mask(seq):\n",
        "    subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n",
        "    subsequent_mask = subsequent_mask.triu(diagonal=1) # upper triangular part of a matrix(2-D)\n",
        "    return subsequent_mask\n",
        "\n",
        "\n",
        "\"\"\" scale dot product attention \"\"\"\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.scale = 1 / (self.config.d_head ** 0.5)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\n",
        "        scores.masked_fill_(attn_mask, -1e9)\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_prob = nn.Softmax(dim=-1)(scores)\n",
        "        attn_prob = self.dropout(attn_prob)\n",
        "        # (bs, n_head, n_q_seq, d_v)\n",
        "        context = torch.matmul(attn_prob, V)\n",
        "        # (bs, n_head, n_q_seq, d_v), (bs, n_head, n_q_seq, n_v_seq)\n",
        "        return context, attn_prob\n",
        "\n",
        "\n",
        "\"\"\" multi head attention \"\"\"\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.W_Q = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_K = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_V = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n",
        "        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_hidn)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        batch_size = Q.size(0)\n",
        "        # (bs, n_head, n_q_seq, d_head)\n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_k_seq, d_head)\n",
        "        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_v_seq, d_head)\n",
        "        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, d_head), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n",
        "        # (bs, n_head, n_q_seq, h_head * d_head)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)\n",
        "        # (bs, n_head, n_q_seq, e_embd)\n",
        "        output = self.linear(context)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_q_seq, d_hidn), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        return output, attn_prob\n",
        "\n",
        "\n",
        "\"\"\" feed forward \"\"\"\n",
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_ff, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=self.config.d_ff, out_channels=self.config.d_hidn, kernel_size=1)\n",
        "        self.active = F.gelu\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # (bs, d_ff, n_seq)\n",
        "        output = self.active(self.conv1(inputs.transpose(1, 2)))\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        output = self.conv2(output).transpose(1, 2)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        return output"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRRKm6mP5YlK"
      },
      "source": [
        "\"\"\" decoder layer \"\"\"\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(self.config)\n",
        "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
        "        self.layer_norm3 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "    \n",
        "    def forward(self, dec_inputs, self_attn_mask):\n",
        "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq)\n",
        "        self_att_outputs, self_attn_prob = self.self_attn(dec_inputs, dec_inputs, dec_inputs, self_attn_mask)\n",
        "        self_att_outputs = self.layer_norm1(dec_inputs + self_att_outputs)\n",
        "        # (bs, n_dec_seq, d_hidn)\n",
        "        ffn_outputs = self.pos_ffn(self_att_outputs)\n",
        "        ffn_outputs = self.layer_norm3(self_att_outputs + ffn_outputs)\n",
        "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq), (bs, n_head, n_dec_seq, n_enc_seq)\n",
        "        return ffn_outputs, self_attn_prob\n",
        "\n",
        "\n",
        "\"\"\" decoder \"\"\"\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.dec_emb = nn.Embedding(self.config.n_dec_vocab, self.config.d_hidn)\n",
        "        sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_dec_seq + 1, self.config.d_hidn))\n",
        "        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n",
        "\n",
        "        self.layers = nn.ModuleList([DecoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
        "    \n",
        "    def forward(self, dec_inputs):\n",
        "        positions = torch.arange(dec_inputs.size(1), device=dec_inputs.device, dtype=dec_inputs.dtype).expand(dec_inputs.size(0), dec_inputs.size(1)).contiguous() + 1\n",
        "        pos_mask = dec_inputs.eq(self.config.i_pad)\n",
        "        positions.masked_fill_(pos_mask, 0)\n",
        "    \n",
        "        # (bs, n_dec_seq, d_hidn)\n",
        "        dec_outputs = self.dec_emb(dec_inputs) + self.pos_emb(positions)\n",
        "\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs, self.config.i_pad)\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_attn_decoder_mask = get_attn_decoder_mask(dec_inputs)\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_self_attn_mask = torch.gt((dec_attn_pad_mask + dec_attn_decoder_mask), 0)\n",
        "\n",
        "        self_attn_probs = []\n",
        "        for layer in self.layers:\n",
        "            # (bs, n_dec_seq, d_hidn), (bs, n_dec_seq, n_dec_seq)\n",
        "            dec_outputs, self_attn_prob = layer(dec_outputs, dec_self_attn_mask)\n",
        "            self_attn_probs.append(self_attn_prob)\n",
        "        # (bs, n_dec_seq, d_hidn), [(bs, n_dec_seq, n_dec_seq)]\n",
        "        return dec_outputs, self_attn_probs\n",
        "\n",
        "\n",
        "\"\"\" gpt \"\"\"\n",
        "class GPT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.decoder = Decoder(self.config)\n",
        "    \n",
        "    def forward(self, dec_inputs):\n",
        "        # (bs, n_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
        "        dec_outputs, dec_self_attn_probs = self.decoder(dec_inputs)\n",
        "        # (bs, n_dec_seq, n_dec_vocab), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
        "        return dec_outputs, dec_self_attn_probs\n",
        "    \n",
        "    def save(self, epoch, loss, path):\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"loss\": loss,\n",
        "            \"state_dict\": self.state_dict()\n",
        "        }, path)\n",
        "    \n",
        "    def load(self, path):\n",
        "        save = torch.load(path)\n",
        "        self.load_state_dict(save[\"state_dict\"])\n",
        "        return save[\"epoch\"], save[\"loss\"]"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxBxdffT5jgM"
      },
      "source": [
        "#### 7. Naver 영화 분류 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UZfJ4cA5vED"
      },
      "source": [
        "\"\"\" naver movie classfication \"\"\"\n",
        "class MovieClassification(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.gpt = GPT(self.config)\n",
        "        # lm\n",
        "        self.projection_lm = nn.Linear(self.config.d_hidn, self.config.n_dec_vocab, bias=False)\n",
        "        self.projection_lm.weight = self.gpt.decoder.dec_emb.weight\n",
        "        # classfier\n",
        "        self.projection_cls = nn.Linear(self.config.d_hidn, self.config.n_output, bias=False)\n",
        "    \n",
        "    def forward(self, dec_inputs):\n",
        "        # (bs, n_dec_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
        "        dec_outputs, dec_self_attn_probs = self.gpt(dec_inputs)\n",
        "        # (bs, n_dec_seq, n_dec_vocab)\n",
        "        logits_lm = self.projection_lm(dec_outputs)\n",
        "        # (bs, d_hidn)\n",
        "        dec_outputs = dec_outputs[:, -1].contiguous()\n",
        "        # (bs, n_output)\n",
        "        logits_cls = self.projection_cls(dec_outputs)\n",
        "        # (bs, n_dec_seq - 1, n_dec_vocab), (bs, n_output), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
        "        return logits_lm[:, :-1, :].contiguous(), logits_cls, dec_self_attn_probs"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mfdsArh6ACW"
      },
      "source": [
        "#### 8. 네이버 영화 분류 데이터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWgT4EgiF9ku"
      },
      "source": [
        "def clean_text(sent):\n",
        "    sent_clean = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\", \"\", sent)\n",
        "    return sent_clean"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCrJb3986Bsl"
      },
      "source": [
        "\"\"\" 영화 분류 데이터셋 \"\"\"\n",
        "class MovieDataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, vocab, infile):\n",
        "        self.vocab = vocab\n",
        "        self.labels = []\n",
        "        self.sentences = []\n",
        "\n",
        "        line_cnt = 0\n",
        "        with open(infile, \"r\") as f:\n",
        "            for line in f:\n",
        "                line_cnt += 1\n",
        "\n",
        "        with open(infile, \"r\") as f:\n",
        "            for i, line in enumerate(tqdm(f, total=line_cnt, desc=f\"Loading {infile}\", unit=\" lines\")):\n",
        "                data = json.loads(line)\n",
        "                self.labels.append(data[\"label\"]) \n",
        "                # self.sentences.append([vocab.token_to_idx[p] for p in vocab[\"tokens\"]])\n",
        "                text = [vocab[tokenizer(str(s))] for s in data[\"doc\"] if s != \" \"]\n",
        "                self.sentences.append([vocab[vocab.bos_token],]  + [y for x in text for y in x] + [vocab[vocab.eos_token],])\n",
        "                ###여기서 generator가 만들어져서 아래에 next를 추가함\n",
        "                # self.sentences.append([vocab.piece_to_id(\"[BOS]\")] + [vocab.piece_to_id(p) for p in data[\"doc\"]] + [vocab.piece_to_id(\"[EOS]\")])\n",
        "    \n",
        "    def __len__(self):\n",
        "        assert len(self.labels) == len(self.sentences)\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        # return (torch.tensor(self.sentences[item]), torch.tensor(item))\n",
        "        return (torch.tensor(self.labels[item]),\n",
        "                torch.tensor(self.sentences[item]))  \n",
        "                # torch.tensor(np.fromiter(self.sentences[item]), torch.float))"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeZRPgX86IAO"
      },
      "source": [
        "\"\"\" movie data collate_fn \"\"\"\n",
        "def movie_collate_fn(inputs):\n",
        "    labels, dec_inputs = list(zip(*inputs))\n",
        "\n",
        "    dec_inputs = torch.nn.utils.rnn.pad_sequence(dec_inputs, batch_first=True, padding_value=vocab[vocab.padding_token])\n",
        "\n",
        "    batch = [\n",
        "        torch.stack(labels, dim=0),\n",
        "        dec_inputs,\n",
        "    ]\n",
        "    return batch"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELEkz72f6LWM",
        "outputId": "baaad3f3-f871-4130-fc01-77660ab2a90c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"\"\" 데이터 로더 \"\"\"\n",
        "batch_size = 16\n",
        "train_dataset = MovieDataSet(vocab, f\"{data_dir}/ratings_train.json\")\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=movie_collate_fn)\n",
        "test_dataset = MovieDataSet(vocab, f\"{data_dir}/ratings_test.json\")\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=movie_collate_fn)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading /content/drive/My Drive/ModelCollection/transformer-evolution/ratings_train.json: 100%|██████████| 149995/149995 [00:18<00:00, 8257.84 lines/s]\n",
            "Loading /content/drive/My Drive/ModelCollection/transformer-evolution/ratings_test.json: 100%|██████████| 49997/49997 [00:05<00:00, 8500.61 lines/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8G99g8qqPo1",
        "outputId": "fbbc5dcb-9f23-4f39-d7cf-ff3e89c4aab5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "movie_collate_fn(train_dataset)[1][1][1]"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(47437)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LQicLLH6SjV"
      },
      "source": [
        "#### 9. 네이버 영화 분류 데이터 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGSeFztV6aZN"
      },
      "source": [
        "\"\"\" 모델 epoch 평가 \"\"\"\n",
        "def eval_epoch(config, model, data_loader):\n",
        "    matchs = []\n",
        "    model.eval()\n",
        "\n",
        "    n_word_total = 0\n",
        "    n_correct_total = 0\n",
        "    with tqdm(total=len(data_loader), desc=f\"Valid\") as pbar:\n",
        "        for i, value in enumerate(data_loader):\n",
        "            labels, dec_inputs = map(lambda v: v.to(config.device), value)\n",
        "\n",
        "            outputs = model(dec_inputs)\n",
        "            logits_cls = outputs[1]\n",
        "            _, indices = logits_cls.max(1)\n",
        "\n",
        "            match = torch.eq(indices, labels).detach()\n",
        "            matchs.extend(match.cpu())\n",
        "            accuracy = np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Acc: {accuracy:.3f}\")\n",
        "    return np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFWTUIR66ftW"
      },
      "source": [
        "\"\"\" 모델 epoch 학습 \"\"\"\n",
        "def train_epoch(config, epoch, model, criterion_cls, optimizer, train_loader):\n",
        "    losses = []\n",
        "    model.train()\n",
        "\n",
        "    with tqdm(total=len(train_loader), desc=f\"Train({epoch})\") as pbar:\n",
        "        for i, value in enumerate(train_loader):\n",
        "            labels, dec_inputs = map(lambda v: v.to(config.device), value)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(dec_inputs)\n",
        "            logits_cls = outputs[1]\n",
        "\n",
        "            loss_cls = criterion_cls(logits_cls, labels)\n",
        "            loss = loss_cls\n",
        "\n",
        "            loss_val = loss_cls.item()\n",
        "            losses.append(loss_val)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Loss: {loss_val:.3f} ({np.mean(losses):.3f})\")\n",
        "    return np.mean(losses)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn1k7DA26jqd",
        "outputId": "a235a448-2291-4429-a1e3-cb8580da0162",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# config.device = torch.device(\"cpu\")\n",
        "config.n_output = 2\n",
        "print(config)\n",
        "\n",
        "learning_rate = 5e-5\n",
        "n_epoch = 10"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_dec_vocab': 50000, 'n_dec_seq': 256, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 3, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12, 'device': device(type='cuda'), 'n_output': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E14Aflfr6ncx"
      },
      "source": [
        "def train(model):\n",
        "    model.to(config.device)\n",
        "\n",
        "    criterion_cls = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    best_epoch, best_loss, best_score = 0, 0, 0\n",
        "    losses, scores = [], []\n",
        "    for epoch in range(n_epoch):\n",
        "        loss = train_epoch(config, epoch, model, criterion_cls, optimizer, train_loader)\n",
        "        score = eval_epoch(config, model, test_loader)\n",
        "\n",
        "        losses.append(loss)\n",
        "        scores.append(score)\n",
        "\n",
        "        if best_score < score:\n",
        "            best_epoch, best_loss, best_score = epoch, loss, score\n",
        "    print(f\">>>> epoch={best_epoch}, loss={best_loss:.5f}, socre={best_score:.5f}\")\n",
        "    return losses, scores"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD9vVobmAad2"
      },
      "source": [
        "###### Pretrain 없이 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB2JQ8wlIvPZ"
      },
      "source": [
        "#cuda update \n"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fldSawzz7wUL",
        "outputId": "82e19483-7bc1-4d7a-af4f-e6de8d390b9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "model = MovieClassification(config)\n",
        "\n",
        "losses_00, scores_00 = train(model)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-a021dde5eab1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMovieClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlosses_00\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_00\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-81-bb033ad0483b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcriterion_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Module'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_grad_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_grad_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     ) -> RemovableHandle:\n\u001b[0;32m--> 612\u001b[0;31m         r\"\"\"Registers a backward hook on the module.\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mwarning\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_compatible_shallow_copy_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;31m# If the new tensor has compatible tensor type as the existing tensor,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                 \u001b[0;31m# the current behavior is to change the tensor in-place using `.data =`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;31m# and the future behavior is to overwrite the existing tensor. However,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0;31m# changing the current behavior is a BC-breaking change, and we want it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_compatible_shallow_copy_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;31m# If the new tensor has compatible tensor type as the existing tensor,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                 \u001b[0;31m# the current behavior is to change the tensor in-place using `.data =`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;31m# and the future behavior is to overwrite the existing tensor. However,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0;31m# changing the current behavior is a BC-breaking change, and we want it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_compatible_shallow_copy_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;31m# If the new tensor has compatible tensor type as the existing tensor,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                 \u001b[0;31m# the current behavior is to change the tensor in-place using `.data =`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;31m# and the future behavior is to overwrite the existing tensor. However,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0;31m# changing the current behavior is a BC-breaking change, and we want it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_leaf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_applied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     def register_backward_hook(\n\u001b[0;32m--> 610\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Module'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_grad_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_grad_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m     ) -> RemovableHandle:\n\u001b[1;32m    612\u001b[0m         r\"\"\"Registers a backward hook on the module.\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHTz0Y62AhYT"
      },
      "source": [
        "###### Pretrain을 한 후 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkpvZ96X7w0I"
      },
      "source": [
        "model = MovieClassification(config)\n",
        "\n",
        "save_pretrain = f\"{data_dir}/save_gpt_pretrain.pth\"\n",
        "model.gpt.load(save_pretrain)\n",
        "\n",
        "losses_20, scores_20 = train(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlJEPOFi07qW"
      },
      "source": [
        "#### 10. Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVDJVY9asQsO"
      },
      "source": [
        "# table\n",
        "data = {\n",
        "    \"loss_00\": losses_00,\n",
        "    \"socre_00\": scores_00,\n",
        "    \"loss_20\": losses_20,\n",
        "    \"socre_20\": scores_20,\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "display(df)\n",
        "\n",
        "# graph\n",
        "plt.figure(figsize=[12, 4])\n",
        "plt.plot(scores_00, label=\"score_00\")\n",
        "plt.plot(scores_20, label=\"score_20\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Value')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEHCUhhtv_8g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}